trees
plot(trees.lda)
data()
summary(trees.lda)
trees.lda
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
trees.lda <- lda.qda.cv(trees, Girth~., 10, Volume, lda)
library(MASS)
trees.lda <- lda.qda.cv(trees, Girth~., 10, Volume, lda)
trees
trees.lda <- lda.qda.cv(trees, Girth~., 10, Girth, lda)
trees.lda <- lda.qda.cv(trees, Girth~., 10, 3, lda)
iris
data()
Pima.tr
Pima.tr.lda <- lda.qda.cv(Pima.tr, age~., 10, 5, lda)
Pima.tr.lda
Pima.tr.lda <- lda.qda.cv(Pima.tr, age~., 10, 5, qda)
Pima.tr.qda <- qda(age~., data=Pima.tr)
help("Pima.tr")
Pima.tr.qda <- qda(age~glu+bmi, data=Pima.tr)
diabetes
library(mclust)
pkg.install(mclust)
install.packages(mclust)
library(mclust)
install.packages("mclust")
library(mclust)
data(diabetes)
diabetes.lda <- lda(class~insulin+glucose+sspg, data=diabetes, CV=TRUE)
diabetes
help("diabetes")
diabetes.lda <- lda(diabetes, class~insulin+glucose, 10, sspg, lda)
\
diabetes.lda <- lda(diabetes, class~insulin+glucose+sspg, 10, sspg, lda)
help("lda")
lda.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = lda(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
diabetes.lda <- lda.qda.cv(diabetes, class~insulin+glucose+sspg, 10, sspg, lda)
diabetes.lda <- lda.qda.cv(diabetes, class~insulin+glucose+sspg, 10, 4, lda)
diabetes.lda
diabetes.qda <- lda.qda.cv(diabetes, class~insulin+glucose+sspg, 10, 4, qda)
diabetes.qda <- lda.qda.cv(diabetes, class~insulin+glucose, 10, 4, qda)
diabetes.qda <- lda.qda.cv(diabetes, class~insulin+glucose, 10, 4, qda)
diabetes.lda <- lda.qda.cv(diabetes, class~insulin+glucose, 10, 4, lda)
diabetes[4]
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
help("Pima.tr")
Pima.tr.lda <- lda.qda.cv(Pima.tr, age~bmi+npreg+skin, 10, 2, lda)
Pima.tr.lda <- lda.qda.cv(Pima.tr, age~bmi+npreg+skin, 10, 2, 1da)
Pima.tr.lda <- lda.qda.cv(Pima.tr, age~bmi+npreg+skin, 10, 2, qda)
Pima.tr.qda <- qda(age~bmi+npreg+skin, data=Pima.tr)
Pima.tr.qda <- qda(age~bmi+npreg+skin, data=Pima.tr, CV=FALSE)
help("diabetes")
diabetes.lda <- lda(class~glucose+insulin, data=Pima.tr)
diabetes.lda <- lda(class~glucose+insulin, data=diabetes)
diabetes.lda
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
diabetes.lda
cv.glm
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
print(myguess)
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
print(myguess)
temp[j] = mean(myguess != mydata[testind,ycol])
}
print(temp)
cv = mean(temp)
return(cv)
}
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
print(myguess)
temp[j] = mean(myguess != mydata[testind,ycol])
print(temp[j])
}
cv = mean(temp)
return(cv)
}
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
print(myguess)
print(myguess != mydata[testind,ycol])
temp[j] = mean(myguess != mydata[testind,ycol])
print(temp[j])
}
cv = mean(temp)
return(cv)
}
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin+sspg, 10, 4, lda)
hat.lda <- predict(diabetes.lda)$x
diabetes.lda <- lda(class~insulin+glucose+sspg, data=diabetes)
hat.lda <- predict(diabetes.lda)$x
hat.lda
plot(hat.lda)
diabetes.lda <-lda.qda.cv(diabetes, sspg~glucose+insulin, 10, 4, lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$x # here
print(myguess)
print(myguess != mydata[testind,ycol])
temp[j] = mean(myguess != mydata[testind,ycol])
print(temp[j])
}
cv = mean(temp)
return(cv)
}
diabetes.lda <-lda.qda.cv(diabetes, class~glucose+insulin, 10, 4, lda)
diabetes.lda <-lda.qda.cv(diabetes, class~., 10, 4, lda)
data("iris")
help("iris")
library(MASS)
data("iris")
iris
iris.lda <- lda(Species~., data=iris)
summary(iris.lda)
lda.qda.cv <- function(mydata,myformula,cvfold,ycol,FUN) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = FUN(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.lda <- lda.qda.cv(iris, Species ~., 10, 3, lda)
iris.lda <- lda.qda.cv(iris, Species ~., 10, 5, lda)
iris.lda <- lda.qda.cv(iris, Species ~., 10, 4, lda)
iris.lda <- lda.qda.cv(iris, Species ~., 10, 5, lda)
iris.qda <- lda.qda.cv(iris, Species ~., 10, 5, qda)
iris.nb <- naive_bayes(Species~., data=iris)
iris.nb <- naivebayes::naive_bayes(Species~., data=iris)
iris.nb
naivebayes.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = naivebayes::naive_bayes(myformula,trainset) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.nb <- naivebayes.cv(iris, Species~., 10, 5)
naivebayes.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = naivebayes::naive_bayes(myformula,trainset) # here
myguess = predict(myfit,testset) # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.nb <- naivebayes.cv(iris, Species~., 10, 5)
iris.nb
knn.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = knn(trainset,testset) # here
myguess = predict(myfit,testset) # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.knn <- knn.cv(iris, Species~., 10, 5)
??knn
library(caret)
iris.knn <- knn.cv(iris, Species~., 10, 5)
}
knn.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = knn3(trainset,testset) # here
myguess = predict(myfit,testset) # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.knn <- knn.cv(iris, Species~., 10, 5)
knn.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = knn3(myformula, trainset, k=25) # here
myguess = predict(myfit,testset)$class # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.knn <- knn.cv(iris, Species~., 10, 5)
knn.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
# FUN lda or qda
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = knn3(myformula, trainset, k=25) # here
myguess = predict(myfit,testset, type="class") # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.knn <- knn.cv(iris, Species~., 10, 5)
naivebayes.cv <- function(mydata,myformula,cvfold,ycol) {
# mydata is the data frame
# myformula is our formula
# cvfold, usually 5 or 10
# ycol index of column in mydata we are trying to predict
n = length(mydata[,1])
rord = sample(1:n)
sz = round(n/cvfold)
temp = 1:cvfold
for (j in 1:cvfold) {
lo = ((j-1)*sz) + 1
hi = j*sz
if (j == cvfold) { hi = n }
testind = rord[lo:hi]
testset = mydata[testind,]
trainset = mydata[-testind,]
myfit = naivebayes::naive_bayes(myformula,trainset) # here
myguess = predict(myfit,testset, type="class") # here
temp[j] = mean(myguess != mydata[testind,ycol])
}
cv = mean(temp)
return(cv)
}
iris.nb <- naivebayes.cv(iris, Species~., 10, 5)
help("iris")
iris.nb <- naivebayes.cv(iris, Species~., 10, 4)
iris.nb <- naivebayes.cv(iris, Species~., 10, 1)
iris.nb <- naivebayes.cv(iris, Species~., 10, 5)
iris.lda <- lda.qda.cv(iris, Species~., 10, 5, lda)
iris.qda <- lda.qda.cv(iris, Species~., 10, 5, qda)
setwd("~/GitHub/QBIO499/Project/mybrack")
b1 = read.table("b1.bracken", sep="\t", header=T)
plot(b1[,1])
plot(b1)
plot(b1[,7])
aboveThres <- function(table, th){
species = table[,1]
freq = table[,7]
return(species[freq > th])
}
aboveThres(b1, 0.01)
b1th = aboveThres(b1, 0.01)
size(b1th)
length(b1th)
